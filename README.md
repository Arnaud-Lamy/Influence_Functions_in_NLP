I surveyed and synthesized the field of influence functions and its applications to NLP for a course project for COMS 4774: Unsupervised Learning, a Columbia course taught by Prof. Nakul Verma. Influence functions are a cutting-edge tool for interpreting machine learning models by relating a test-time prediction to the specific data which influenced that prediction. Furthermore, this work considers the utility of influence functions as a defense against data-poisoning attacks, where a malicious adversary may tamper a dataset to deteriorate test-time performance. Inspired by the proliferation of black-box LLMs, this work is grouded in NLP. This work describes some data poisoning attacks for LLMs, accurately details influence functions and their mathematical foundation (relating to their inception in Robust Statistics), and experimentally verifies the utility of Influence Functions as a defense against a toy data-poisoning attack.
